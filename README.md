# What is uInference?
uInference is a project which could run DNN on micro-chip like STM32 etc.

# Usage
1. Run `python2 convert_model.py` to convert the model to the .dat file.
2. make to create, and run the bin.
3. Run `predict.py` to run the example.jpg, compare the results.


# DNN model example
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 16, 16, 8)         208       
_________________________________________________________________
batch_normalization_1 (Batch (None, 16, 16, 8)         32        
_________________________________________________________________
activation_1 (Activation)    (None, 16, 16, 8)         0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 8)           0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 16)          3216      
_________________________________________________________________
batch_normalization_2 (Batch (None, 8, 8, 16)          64        
_________________________________________________________________
activation_2 (Activation)    (None, 8, 8, 16)          0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 2, 16)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                650       
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,170
Trainable params: 4,122
Non-trainable params: 48

## Check leakage:
```
valgrind --tool=memcheck --leak-check=full --show-leak-kinds=all -v ./uInference.bin
```
Check memory:
```
valgrind --tool=massif ./uInference.bin
ms_print massif.out.*
```
[[126 138 133 119 114 111 112 121 117 116 108 108 113 107 104 115]
 [113 113 107 106 114 113 105 102 108 109 106 104 105  99  96 104]
 [108 102  96  96 100 100  98  98 106 113 117 117 113 104  93  86]
 [103 101 101  96  85  92 119 139 150 155 162 161 153 142 116  85]
 [ 89  90 100  98  89 114 158 181 187 183 184 182 179 181 155 107]
 [ 87  83  93  98 102 141 176 173 149 136 133 135 149 182 175 126]
 [ 87  82  91  93 102 149 175 149 107  93  94  97 118 167 175 125]
 [ 78  78  89  86  91 145 177 148 123 111 113 112 124 169 174 120]
 [ 72  81  87  80  84 123 163 172 167 152 160 167 167 180 155  88]
 [ 76  79  80  77  93 139 169 165 164 155 161 160 158 178 165 109]
 [ 81  78  75  74  98 141 151 125  95  89  88  81  94 144 166 137]
 [ 77  75  73  76 101 139 137 100  83  83  78  68  84 135 160 139]
 [ 70  69  70  75  98 136 144 121  93 105 111 110 122 144 136 105]
 [ 72  66  65  67  79 112 135 133 131 143 147 145 147 144 120  92]
 [ 71  62  62  64  63  78 102 113 132 136 127 114 103  82  60  49]
 [ 60  54  62  70  63  64  82  94  98 108 111 110 102  79  62  66]]